---
title: "Statistique bivariée"
---


```{r options_communes, include=FALSE}
source("options_communes.R")
knitr::opts_chunk$set(fig.path = 'images/analyses_stat_biv/')
```

<div class="note">
La version originale de ce chapitre a été écrite par Julien Barnier dans le cadre du support de cours
[Introduction à R](https://github.com/juba/intro-r).
</div>

On entend par statistique bivariée l'étude des relations entre deux variables, celles-ci pouvant être
quantitatives ou qualitatives.

Comme dans la partie précédente, on travaillera sur les jeux de données fournis avec l'extension
<strong class="package">questionr</strong> et tiré de l'enquête *Histoire de vie* et du recensement 1999 :

```{r}
library(questionr)
data(hdv2003)
d <- hdv2003
data(rp99)
```

## Deux variables quantitatives

La comparaison de deux variables quantitatives se fait en premier lieu graphiquement, en représentant
l'ensemble des couples de valeurs. On peut ainsi représenter les valeurs du nombre d'heures passées devant
la télévision selon l'âge.

<figure>
```{r}
plot(d$age, d$heures.tv)
```
<figcaption>Nombre d'heures de télévision selon l'âge</figcaption>
</figure>

Le fait que des points sont superposés ne facilite pas la lecture du graphique. On peut utiliser une
représentation avec des points semi-transparents.

<figure>
```{r}
plot(d$age, d$heures.tv, pch = 19, col = rgb(1, 0, 0, 0.1))
```
<figcaption>Nombre d'heures de télévision selon l'âge avec semi-transparence</figcaption>
</figure>

Plus sophistiqué, on peut faire une estimation locale de densité et représenter le résultat sous forme
de « carte ». Pour cela on commence par isoler les deux variables, supprimer les observations ayant au
moins une valeur manquante à l'aide de la fonction `complete.cases`{data-package="stats"}, 
estimer la densité locale à l'aide de la fonction `kde2d`{data-package="MASS"} de l'extension 
<strong class="package">MASS</strong>^[<strong class="package">MASS</strong> est installée par défaut 
avec la version de base de **R**.] et représenter le tout à l'aide d'une des fonctions 
`image`{data-package="graphics"}, `contour`{data-package="graphics"} ou 
`filled.contour`{data-package="graphics"}. . . 

<figure>
```{r}
library(MASS)
tmp <- d[, c("age", "heures.tv")]
tmp <- tmp[complete.cases(tmp), ]
filled.contour(kde2d(tmp$age, tmp$heures.tv), color = terrain.colors)
```
<figcaption>Représentation de l'estimation de densité locale</figcaption>
</figure>

Dans tous les cas, il n'y a pas de structure très nette qui semble se dégager. On peut tester ceci
mathématiquement en calculant le coefficient de corrélation entre les deux variables à l'aide de la fonction
`cor`{data-package="stats"} :

```{r}
cor(d$age, d$heures.tv, use = "complete.obs")
```

L'option `use` permet d'éliminer les observations pour lesquelles l'une des deux valeurs est manquante.
Le coefficient de corrélation est très faible.

On va donc s'intéresser plutôt à deux variables présentes dans le jeu de données `rp99`, la part de
diplômés du supérieur et la proportion de cadres dans les communes du Rhône en 1999.

À nouveau, commençons par représenter les deux variables.

<figure>
```{r}
plot(rp99$dipl.sup, rp99$cadres, ylab = "Part des cadres", xlab = "Part des diplomês du supérieur")
```
<figcaption>Proportion de cadres et proportion de diplômés du supérieur</figcaption>
</figure>

Ça ressemble déjà beaucoup plus à une relation de type linéaire.

Calculons le coefficient de corrélation :

```{r}
cor(rp99$dipl.sup, rp99$cadres)
```

C'est beaucoup plus proche de 1. On peut alors effectuer une régression linéaire complète en utilisant
la fonction `lm`{data-package="stats"} :

```{r}
reg <- lm(cadres ~ dipl.sup, data = rp99)
summary(reg)
```

Le résultat montre que les coefficients sont significativement différents de 0. La part de cadres augmente
donc avec celle de diplômés du supérieur (ô surprise). On peut très facilement représenter la droite de
régression à l'aide de la fonction `abline`{data-package="graphics"}.

<figure>
```{r}
plot(rp99$dipl.sup, rp99$cadres, ylab = "Part des cadres", xlab = "Part des diplômés du supérieur")
abline(reg, col = "red")
```
<figcaption>Régression de la proportion de cadres par celle de diplômés du supérieur</figcaption>
</figure>

<div class="info">
On remarquera que le premier argument passé à la fonction `lm`{data-package="stats"} a une syntaxe 
un peu particulière. Il s'agit d'une *formule*, utilisée de manière générale dans les modèles statistiques. 
On indique la variable d'intérêt à gauche et la variable explicative à droite, les deux étant séparées par 
un tilde `˜` (obtenu sous **Windows** en appuyant simultanément sur les touches 
<kbd>Alt Gr</kbd> et <kbd>2</kbd>). On remarquera que les noms des colonnes de notre
tableau de données ont été écrites sans guillemets. 

Dans le cas présent, nous avons calculé une régression linéaire
simple entre deux variables, d'où l'écriture `cadres ˜ dipl.sup`. Si nous avions voulu expliquer une variable *z*
par deux variables *x* et *y*, nous aurions écrit `z ˜ x + y`. Il est possible de spécifier des modèles encore plus
complexes.

Pour un aperçu de la syntaxe des formules sous **R**, 
voir <http://ww2.coastal.edu/kingw/statistics/R-tutorials/formulae.html>.
</div>

## Une variable quantitative et une variable qualitative

### Représentations graphiques

Quand on parle de comparaison entre une variable quantitative et une variable qualitative, on veut
en général savoir si la distribution des valeurs de la variable quantitative est la même selon les modalités
de la variable qualitative. En clair : est ce que l'âge de ceux qui écoutent du hard rock est différent de
l'âge de ceux qui n'en écoutent pas ?

Là encore, l'idéal est de commencer par une représentation graphique. Les boîtes à moustaches sont
parfaitement adaptées pour cela.

Si on a construit des sous-populations d'individus écoutant ou non du hard rock, on peut utiliser la
fonction `boxplot`{data-package="graphics"}.

<figure>
```{r}
d.hard <- subset(d, hard.rock == "Oui")
d.non.hard <- subset(d, hard.rock == "Non")
boxplot(d.hard$age, d.non.hard$age)
```
<figcaption>Boxplot de la répartition des âges (sous-populations)</figcaption>
</figure>


Mais construire les sous-populations n'est pas nécessaire. On peut utiliser directement la version de
`boxplot`{data-package="graphics"} prenant une formule en argument.

<figure>
```{r}
boxplot(age ~ hard.rock, data = d)
```
<figcaption>Boxplot de la répartition des âges (formule)</figcaption>
</figure>

À première vue, ô surprise, la population écoutant du hard rock a l'air sensiblement plus jeune. Peut-on
le tester mathématiquement ? 

### Comparaison de moyennes

On peut calculer la moyenne d'âge des deux groupes en utilisant la
fonction `tapply`{data-package="base"}^[La fonction `tapply`{data-package="base"} est présentée plus en 
détails dans le chapitre [Manipulation de données](pem_manipulation.html#tapply).] :

```{r}
tapply(d$age, d$hard.rock, mean)
```

L'écart est important. Est-il statistiquement significatif ? Pour cela on peut faire un test *t* de
comparaison de moyennes à l'aide de la fonction `t.test`{data-package="stats"} :

```{r}
t.test(d$age ~ d$hard.rock)
```

Le test est extrêmement significatif. L'intervalle de confiance à 95 % de la différence entre les deux
moyennes va de 14,5 ans à 21,8 ans.

<div class="info">
La valeur affichée pour *p* est de `1.611e-07`. Cette valeur peut paraître étrange pour les non avertis. Cela
signifie tout simplement 1,611 multiplié par 10 à la puissance -7, autrement dit 0,0000001611. Cette manière
de représenter un nombre est couramment appelée *notation scientifique*. 

Pour plus de détails, voir <http://fr.wikipedia.org/wiki/Notation_scientifique>.
</div>

Nous sommes cependant allés un peu vite en besogne, car nous avons négligé une hypothèse fondamentale
du test *t* : les ensembles de valeur comparés doivent suivre approximativement une loi normale
et être de même variance^[Concernant cette seconde condition, `t.test`{data-package="stats"} propose 
une option nommée `var.equal` qui permet d'utiliser une approximation
dans le cas où les variances ne sont pas égales]. Comment le vérifier ?

D'abord avec un petit graphique :

<figure>
```{r}
par(mfrow = c(1, 2))
hist(d$age[d$hard.rock == "Oui"], main = "Hard rock", col = "red")
hist(d$age[d$hard.rock == "Non"], main = "Sans hard rock", col = "red")
```
<figcaption>Distribution des âges pour appréciation de la normalité</figcaption>
</figure>

<div class="note">
La fonction `par`{data-package="graphics"} permet de modifier de nombreux paramètres graphiques.
`par(mfrow = c(1, 2))` sert à indiquer que l'on souhaite afficher deux graphiques sur une même fenêtre,
plus précisément que la fenêtre doit comporter une ligne et deux colonnes.
</div>

Ça a l'air à peu près bon pour les « Sans hard rock », mais un peu plus limite pour les fans de
*Metallica*, dont les effectifs sont d'ailleurs assez faibles. Si on veut en avoir le coeur net 
on peut utiliser le test de normalité de *Shapiro-Wilk* avec la fonction `shapiro.test`{data-package="stats"} :

```{r}
shapiro.test(d$age[d$hard.rock == "Oui"])
shapiro.test(d$age[d$hard.rock == "Non"])
```

Visiblement, le test estime que les distributions ne sont pas suffisamment proches de la normalité dans
les deux cas.

Et concernant l'égalité des variances ?

```{r}
tapply(d$age, d$hard.rock, var)
```

L'écart n'a pas l'air négligeable. On peut le vérifier avec le test fourni par la fonction 
`var.test`{data-package="stats"} :

```{r}
var.test(d$age ~ d$hard.rock)
```

La différence est très significative. En toute rigueur le test *t* n'aurait donc pas pu être utilisé.

<em lang="en">Damned</em> ! Ces maudits tests statistiques vont-ils nous empêcher de faire connaître au monde entier
notre fabuleuse découverte sur l'âge des fans de *Sepultura* ? Non ! Car voici qu'approche à l'horizon un nouveau
test, connu sous le nom de *Wilcoxon/Mann-Whitney*. Celui-ci a l'avantage d'être non-paramétrique,
c'est à dire de ne faire aucune hypothèse sur la distribution des échantillons comparés. 
Par contre il ne compare pas des différences de moyennes mais des différences de médianes :

```{r}
wilcox.test(d$age ~ d$hard.rock)
```

Ouf ! La différence est hautement significative^[Ce test peut également fournir un intervalle de confiance 
avec l'option `conf.int=TRUE`.]. Nous allons donc pouvoir entamer la rédaction de
notre article pour la *Revue française de sociologie*.

## Deux variables qualitatives

La comparaison de deux variables qualitatives s'appelle en général un *tableau croisé*. C'est sans doute
l'une des analyses les plus fréquentes lors du traitement d'enquêtes en sciences sociales.

### Tableau croisé

La manière la plus simple d'obtenir un tableau croisé est d'utiliser la fonction `table`{data-package="base"}
en lui donnant en paramètres les deux variables à croiser. En l'occurrence nous allons croiser un recodage 
du niveau de qualification regroupé avec le fait de pratiquer un sport.

On commence par calculer la variable recodée et par afficher le tri à plat des deux variables :

```{r}
d$qualreg <- as.character(d$qualif)
d$qualreg[d$qualif %in% c("Ouvrier specialise", "Ouvrier qualifie")] <- "Ouvrier"
d$qualreg[d$qualif %in% c("Profession intermediaire", "Technicien")] <- "Intermediaire"
table(d$qualreg)
```

Le tableau croisé des deux variables s'obtient de la manière suivante :

```{r}
table(d$sport, d$qualreg)
```

<div class="info">
Il est tout à fait possible de croiser trois variables ou plus. Par exemple :

```{r}
table(d$sport, d$cuisine, d$sexe)
```
</div>

On n'a cependant que les effectifs, ce qui rend difficile les comparaisons. 
L'extension <strong class="package">questionr</strong>
fournit des fonctions permettant de calculer facilement les pourcentages lignes, colonnes et totaux d'un tableau croisé.

Les pourcentages lignes s'obtiennent avec la fonction `lprop`{data-package="questionr"data-rdocumentation="rprop"}^[Il 
s'agit en fait d'un alias pour les francophones de la fonction `rprop`{data-package="questionr"}]. 
Celle-ci s'applique au tableau croisé généré par `table`{data-package="base" data-rdocumentation="rprop"} :

```{r}
tab <- table(d$sport, d$qualreg)
lprop(tab)
```

Les pourcentages ligne ne nous intéressent guère ici. On ne cherche pas à voir quelle est la proportion
de cadres parmi ceux qui pratiquent un sport, mais plutôt quelle est la proportion de sportifs chez les
cadres. Il nous faut donc des pourcentages colonnes, que l'on obtient avec la fonction `cprop`{data-package="questionr"} :

```{r}
cprop(tab)
```

Dans l'ensemble, le pourcentage de personnes ayant pratiqué un sport est de 35,6 %. Mais cette
proportion varie fortement d'une catégorie professionnelle à l'autre : 55,0 % chez les cadres contre 23,0 %
chez les ouvriers.

Enfin, les pourcentage totaux s'obtiennent avec la fonction `prop`{data-package="questionr"} :

```{r}
prop(tab)
```


À noter qu'on peut personnaliser l'affichage de ces tableaux de pourcentages à l'aide de différentes
options, dont `digits` qui règle le nombre de décimales à afficher et `percent` qui indique si on souhaite ou
non rajouter un symbole `%` dans chaque case du tableau. Cette personnalisation peut se faire directement
au moment de la génération du tableau et dans ce cas elle sera utilisée par défaut :

```{r}
ctab <- cprop(tab, digits = 2, percent = TRUE)
ctab
```

Ou bien ponctuellement en passant les mêmes arguments à la fonction 
`print`{data-package="questionr" data-rdocumentation="print.proptab"} :

```{r}
ctab <- cprop(tab)
print(ctab, percent = TRUE)
```

### &chi;² et dérivés

Pour tester l'existence d'un lien entre les modalités des deux variables, on va utiliser le très classique
test du &chi;²^[On ne donnera pas plus d'indications sur le test du &chi;² ici. Les personnes désirant une 
présentation plus détaillée pourront se reporter (attention, séance d'autopromotion !) à la page suivante : <http://alea.fr.eu.org/pages/khi2>.]. Celui-ci s'obtient grâce à la fonction `chisq.test`{data-package="stats"},
appliquée au tableau croisé obtenu avec `table`{data-package="base"}^[On peut aussi appliquer directement le test 
en spécifiant les deux variables à croiser via `chisq.test(d$qualreg, d$sport)`.] :

```{r}
chisq.test(tab)
```

Le test est hautement significatif, on ne peut pas considérer qu'il y a indépendance entre les lignes et
les colonnes du tableau.

On peut affiner l'interprétation du test en déterminant dans quelle case l'écart à l'indépendance est
le plus significatif en utilisant les *résidus* du test. Ceux-ci sont notamment affichables avec la fonction
`chisq.residuals`{data-package="questionr"} de <strong class="package">questionr</strong> :

```{r}
chisq.residuals(tab)
```

Les cases pour lesquelles l'écart à l'indépendance est significatif ont un résidu dont la valeur est
supérieure à 2 ou inférieure à -2. Ici on constate que la pratique d'un sport est sur-représentée parmi
les cadres et, à un niveau un peu moindre, parmi les professions intermédiaires, tandis qu'elle est sousreprésentée
chez les ouvriers.

Enfin, on peut calculer le coefficient de contingence de Cramer du tableau, qui peut nous permettre
de le comparer par la suite à d'autres tableaux croisés. On peut pour cela utiliser la fonction 
`cramer.v`{data-package="questionr"} de <strong class="package">questionr</strong> :

```{r}
cramer.v(tab)
```

<div class="info">
Pour un tableau à 2×2 entrées, il est possible de calculer le test exact de Fisher avec la fonction 
`fisher.test`{data-package="stats"}. On peut soit lui passer le résultat de `table`{data-package="base"}, 
soit directement les deux variables à croiser.

```{r}
lprop(table(d$sexe, d$cuisine))
fisher.test(table(d$sexe, d$cuisine))
```
</div>

### Représentation graphique

Enfin, on peut obtenir une représentation graphique synthétisant l'ensemble des résultats obtenus sous
la forme d'un graphique en mosaïque, grâce à la fonction `mosaicplot`{data-package="graphics"}.

<figure>
```{r}
mosaicplot(qualreg ~ sport, data = d, shade = TRUE, main = "Graphe en mosaïque")
```
<figcaption>Exemple de graphe en mosaïque</figcaption>
</figure>

Comment interpréter ce graphique haut en couleurs^[Sauf s'il est imprimé en noir et blanc. . .] ? 
Chaque rectangle représente une case de tableau.
Sa largeur correspond aux pourcentages en colonnes (il y'a beaucoup d'employés et
d'ouvriers et très peu d'« Autre »). Sa hauteur correspond aux pourcentages en lignes : la proportion
de sportifs chez les cadres est plus élevée que chez les employés. Enfin, la couleur de la case correspond
au résidu du test du &chi;² correspondant : les cases en rouge sont sous-représentées, les cases en bleu
sur-représentées, et les cases blanches sont statistiquement proches de l'hypothèse d'indépendance.

Lorsque l'on s'intéresse principalement aux variations d'une variable selon une autre, par exemple ici à
la pratique du sport selon le niveau de qualification, il peut être intéressant de présenter les pourcentages
en colonne sous la forme de barres cumulées.

<figure>
```{r}
barplot(cprop(tab, total = FALSE), main = "Pratique du sport selon le niveau de qualification")
```
<figcaption>Exemple de barres cumulées</figcaption>
</figure>

### Comparaison de proportions

La fonction `prop.test`{data-package="stats"}, que nous avons déjà rencontrer pour 
calculer l'interface de confiance d'une proportion (MAJ_LIEN) permets également de 
comparer deux proportions.

Supposons que l'on souhaite comparer la proportion de personnes faisant du sport entre
ceux qui lisent des bandes dessinées et les autres :

```{r}
lprop(table(d$lecture.bd, d$sport))
```

Il suffit de transmettre notre tableau croisé (à 2×2 dimensions) à `prop.test`{data-package="stats"} :

```{r}
prop.test(table(d$lecture.bd, d$sport))
```
